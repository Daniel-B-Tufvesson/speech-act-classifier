{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train a linear neural network. During the training it is evaluated every 100 batches to measure the effect increasing data has on its performance. It is trained only one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import speechact\n",
    "import speechact.classifier.embedding as emb\n",
    "import speechact.classifier.base as b\n",
    "import speechact.evaluation as evaluation\n",
    "import speechact.corpus as corp\n",
    "import speechact.annotate as anno\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels = [act.value for act in emb.SPEECH_ACTS]\n",
    "\n",
    "# Load upsampled data. Note: the file names are correct even if it does not look like it.\n",
    "test_corpus = corp.Corpus('../data/annotated data/dev-set-sentiment-train-upsampled.conllu.bz2')\n",
    "dev_corpus = corp.Corpus('../data/annotated data/dev-set-sentiment-test-upsampled.conllu.bz2')\n",
    "train_corpus = corp.Corpus('../data/auto-annotated data/speech-acts.conllu.bz2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_histories(loss_history: list[float], dev_loss_history: list[float]):\n",
    "    epochs = range(1, len(loss_history) + 1)\n",
    "    plt.plot(epochs, loss_history, label='Training Loss')\n",
    "    plt.plot(epochs, dev_loss_history, label='Dev Loss')\n",
    "    plt.title('Training and Dev Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history(history: evaluation.TrainAccuracyHistory):\n",
    "    plt.plot(history.data_amount, history.accuracies, label='Training Loss')\n",
    "    plt.title('Accuracy on Dev Data')\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(corpus: corp.Corpus, \n",
    "                dev_corpus: corp.Corpus, \n",
    "                model_name: str,\n",
    "                network_factory: emb.NetworkFactory|None = None,\n",
    "                epochs = 10):\n",
    "    \n",
    "    print('Load classifier')\n",
    "    classifier = emb.EmbeddingClassifier(network_factory=network_factory)\n",
    "\n",
    "    print('Load dataset')\n",
    "    dataset = emb.CorpusDataset(corpus)\n",
    "    dev_dataset = emb.CorpusDataset(dev_corpus)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    loss_history = []\n",
    "    dev_loss_history = []\n",
    "    accuracy_history = evaluation.TrainAccuracyHistory(dev_corpus, classifier, batch_size)\n",
    "    \n",
    "    print(f'Train classifier: {model_name}')\n",
    "    classifier.train(dataset, \n",
    "                     batch_size, \n",
    "                     loss_history=loss_history, \n",
    "                     dev_loss_history=dev_loss_history,\n",
    "                     dev_data=dev_dataset,\n",
    "                     num_epochs=epochs,\n",
    "                     batch_callback=accuracy_history.compute_accuracy,\n",
    "                     callback_each_batch=100,\n",
    "                     use_class_weights=True)\n",
    "    classifier.save(model_name)\n",
    "\n",
    "    plot_loss_histories(loss_history, dev_loss_history)\n",
    "    plot_accuracy_history(accuracy_history)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(corpus: corp.Corpus, \n",
    "                   model_name: str,\n",
    "                   network_factory: emb.NetworkFactory|None = None):\n",
    "    \n",
    "    print('Load classifier')\n",
    "    classifier = emb.EmbeddingClassifier(network_factory=network_factory)\n",
    "    classifier.load(model_name)\n",
    "\n",
    "    print(f'Evaluate classifier: {model_name}')\n",
    "    return evaluation.evaluate(\n",
    "        corpus,\n",
    "        classifier,\n",
    "        labels,\n",
    "        draw_conf_matrix=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load classifier\n",
      "Load dataset\n",
      "Train classifier: ../models/neural/no-hidden/final-model-1-epoch.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: epoch 1/1\", unit=\"batch:  21%|██        | 21438/102932 [4:57:54<11:29:49,  1.97it/s] "
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = '../models/neural/no-hidden/final-model-1-epoch.pth'\n",
    "\n",
    "train_model(train_corpus, \n",
    "            test_corpus, \n",
    "            model_name=model_name,\n",
    "            epochs=1)\n",
    "results = evaluate_model(test_corpus, model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
